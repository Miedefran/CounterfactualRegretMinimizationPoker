\section{Zielerreichung und Limitationen}

In diesem Abschnitt werden die Ergebnisse der Arbeit zusammengefasst und im Hinblick auf die \hyperref[sec:zielsetzung]{Zielsetzung und Fragestellungen aus Kapitel~1.2} eingeordnet.

Es wurden mehrere Pokervarianten in einer einheitlichen Struktur implementiert.
Darauf aufbauend wurden mehrere CFR-Varianten implementiert und in verschiedenen Formen realisiert.
Zur Bewertung der Strategien wurde die Exploitability über einen Best-Response-Agent auf Basis eines Public State Trees berechnet.
Es wurde eine vollständige Pipeline von der Spiellösung bis hin zur Evaluation umgesetzt.

Ein geplantes Ziel wurde nicht erreicht:
Im Exposé war vorgesehen, neben CFR+ auch Sampling-basierte Verfahren (MCCFR) praktisch zu vergleichen.
Diese Algorithmen konnten nicht evaluiert werden, hierfür wurde aber der Algorithmus DCFR als Vergleich hinzugezogen.
Die Gründe hierfür wurden bereits in \hyperref[chap:entwicklungsvorgang]{Kapitel~5} erläutert.

Die drei \hyperref[sec:zielsetzung]{Forschungsfragen aus Kapitel~1.2} können anhand der Ergebnisse beantwortet werden:

\begin{enumerate}
  \item \textbf{Algorithmusvergleich:} 
  Wie unterscheiden sich die verschiedenen CFR-Algorithmen in ihrem Konvergenzverhalten bei steigender Spielgröße, und ab welcher Spielgröße ist Vanilla CFR nicht mehr praktikabel?    

  Die unterschiede im Konvergenzhalten der untersuchten Algorithmen bleiben bei steigender Spielgröße auf einer logarithmischen Skala ähnlich.
  Bei Small Island Hold'em ist Vanilla CFR mit alternierenden Updates nicht mehr praktikabel, da selbst nach 45~Stunden Training keine hinreichend niedrige Exploitability erreicht werden konnte.
  \item \textbf{Implementierungsoptimierungen:} 
  Welche Implementierungsoptimierungen sind erforderlich, damit das Training bei wachsender Spielgröße praktikabel bleibt?

  Es gibt unzählige Implementierungsoptimierungen, die vorgenommen werden können, um die Laufzeit des Algorithmus zu beeinflussen.
  Die meisten beruhen auf paralleler Berechnung.
  In dieser Arbeit wurde eine Layer-basierte Implementierung gewählt, welche bei größer werdenden Spielen essenziell war.
  Jedoch wird jede Methode, die einen statischen Spielbaum benutz, bei wachsender Spielgröße irgendwann durch den Speicherverbrauch beschränkt.
  \item \textbf{Limitationen:} 
  Durch welche Komponenten wird die geplante Implementierung limitiert?

  Die Skalierungsgrenzen sind je nach Implementierungsansatz unterschiedlich.
Die dynamische Implementierung ist durch ihre Laufzeit begrenzt.
Die Layer-basierte Tree-Implementierung ist durch den Speicherverbrauch begrenzt.
Ein weiterer Bottleneck, der bei weiterer Skalierung relevant wird, ist der Best Response Agent.
Dies betrifft zum einen den Speicherbedarf des Public State Trees, aber viel mehr die Laufzeit.
\end{enumerate}

Diese Arbeit bietet einen Einstieg in das Thema \enquote{Computational Game Solving} mittels Counterfactual Regret Minimization.
Die Implementierung bietet eine Pipeline zum Trainieren und Evaluieren von approximativen Nash-Equilibrium Strategien in verschiedenen Pokervarianten.
Um die Ergebnisse greifbarer zu machen, wurde im Rahmen eines anderen Moduls eine grafische Benutzeroberfläche implementiert, in der ein Mensch gegen eine trainierte Strategie spielen kann.
Diese Implementierung ist nicht Teil dieser Bachelorarbeit.
Die Arbeit nutzt diese lediglich, um die Ergebnisse anschaulicher zu machen.
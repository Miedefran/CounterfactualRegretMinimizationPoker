\section{Zielerreichung und Limitationen}

In diesem Abschnitt werden die Ergebnisse der Arbeit zusammengefasst und im Hinblick auf die \hyperref[sec:zielsetzung]{Zielsetzung und Fragestellungen aus Kapitel~1.2} eingeordnet.

Es wurden mehrere Pokervarianten in einer einheitlichen Struktur implementiert.
Darauf aufbauend wurden mehrere CFR-Varianten implementiert und in verschiedenen Formen realisiert.
Zur Bewertung der Strategien wurde die Exploitability über einen Best-Response-Agent auf Basis eines Public State Trees berechnet.
Es wurde eine vollständige Pipeline von der Spiellösung bis hin zur Evaluation umgesetzt.

Ein geplantes Ziel wurde nicht erreicht:
Im Exposé war vorgesehen, neben CFR+ auch Sampling-basierte Verfahren (MCCFR) praktisch zu vergleichen.
Diese Algorithmen konnten nicht evaluiert werden, hierfür wurde aber der Algorithmus DCFR als Vergleich hinzugezogen.
Die Gründe hierfür wurden bereits in \hyperref[chap:entwicklungsvorgang]{Kapitel~5} erläutert.

Die drei \hyperref[sec:zielsetzung]{Forschungsfragen aus Kapitel~1.2} können anhand der erreichten Ergebnisse beantwortet werden:

\begin{enumerate}
  \item \textbf{Algorithmusvergleich:} 
  Wie unterscheiden sich die verschiedenen CFR-Algorithmen in ihrem Konvergenzverhalten bei steigender Spielgröße, und ab welcher Spielgröße ist Vanilla CFR nicht mehr praktikabel?    

  Die Unterschiede im Konvergenzverhalten der untersuchten Algorithmen bleiben bei steigender Spielgröße auf einer logarithmischen Skala ähnlich.
  Bei Small Island Hold'em ist Vanilla CFR mit alternierenden Updates nicht mehr praktikabel, da selbst nach 45~Stunden Training keine hinreichend niedrige Exploitability erreicht werden konnte.
  \item \textbf{Implementierungsoptimierungen:} 
  Welche Implementierungsoptimierungen sind erforderlich, damit das Training bei wachsender Spielgröße praktikabel bleibt?

  Um das Training bei wachsender Spielgröße praktikabel zu halten, sind verschiedene Implementierungsoptimierungen erforderlich.
  Ein wichtiger Aspekt ist der Umstieg auf speichereffiziente Datenstrukturen, wie beispielsweise die Verwendung von NumPy-Arrays statt Python-Objekten.
  Zudem wird irgendeine Form der parallelen Berechnung erforderlich.
  In dieser Arbeit wurde die Layer-basierte Traversierung gewählt, welche eine gesamte Schicht gleichzeitig durch Vektoroperationen parallel verarbeitet.
  Diese Optimierungen ermöglichen es, größere Spiele zu lösen, jedoch wird jede Methode, die einen statischen Spielbaum benutzt, bei wachsender Spielgröße irgendwann durch den Speicherverbrauch beschränkt.
  \item \textbf{Limitationen:} 
  Durch welche Komponenten wird die geplante Implementierung limitiert?

Die Skalierungsgrenzen sind je nach Implementierungsansatz unterschiedlich.
Die dynamische Implementierung ist durch ihre Laufzeit begrenzt.
Die Layer-basierte Tree-Implementierung ist durch den Speicherverbrauch begrenzt.
Ein weiterer Bottleneck, der bei weiterer Skalierung relevant wird, ist der Best Response Agent.
Dies betrifft zum einen den Speicherbedarf des Public State Trees sowie die Laufzeit.
\end{enumerate}

Diese Arbeit bietet einen fundierten Einstieg in das Thema \enquote{Computational Game Solving} mittels Counterfactual Regret Minimization.
Es wurde gezeigt, wie man extensive Spiele mit imperfekter Information mit spieltheoretischen Algorithmen löst.
Darüber hinaus wurden die limitierenden Faktoren für eine weitere Skalierung der Spielgröße herausgearbeitet.
Im folgenden Ausblick wird besprochen, welche Maßnahmen getroffen werden müssen, um die Implementierung weiter zu skalieren.